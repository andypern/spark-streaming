/** note: this only appears to work if you start your netcat listener prior to launching, eg:
nc -lk 9999.  But, to make things more useful, do something like this:
1) mkfifo /mapr/cluster/input
2) tail -f /mapr/cluster/input | nc -lk 9999
3) start this spark app to connect to the port
4) echo/cat stuff into /mapr/cluster/input
This should allow the connection to stay open, and be able to shove whatever you want into the FIFO and have it show up on the spark side.
*/



package org.apache.spark.streaming.andyp
import java.io._
import scala.io.Source
import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.storage.StorageLevel



/** probably better to package the logging function up as a separate class, but for now this is fine */

import org.apache.spark.Logging
import org.apache.log4j.{Level, Logger}

/** Utility functions for Spark Streaming examples. */
object StreamingExamples extends Logging {

  /** Set reasonable logging levels for streaming if the user has not configured log4j. */
  def setStreamingLogLevels() {
    val log4jInitialized = Logger.getRootLogger.getAllAppenders.hasMoreElements
    if (!log4jInitialized) {
      // We first log something to initialize Spark's default logging, then we override the
      // logging level.
      logInfo("Setting log level to [WARN] for streaming example." +
        " To override add a custom log4j.properties to the classpath.")
      Logger.getRootLogger.setLevel(Level.WARN)
    }
    Logger.getRootLogger.setLevel(Level.WARN)
  }
}


/** now to the actual work..borrowed from spark streaming examples */

object NetworkWordCount {
  def main(args: Array[String]) {
    if (args.length < 3) {
      System.err.println("Usage: NetworkWordCount <master> <hostname> <port>\n" +
        "In local mode, <master> should be 'local[n]' with n > 1")
      System.exit(1)
    }

    StreamingExamples.setStreamingLogLevels()

    // Create the context with a 1 second batch size
    val ssc = new StreamingContext(args(0), "NetworkWordCount", Seconds(1),
      System.getenv("SPARK_HOME"), StreamingContext.jarOfClass(this.getClass))



    //not needed, since we can get it via the arg's.

    //val lines = ssc.socketTextStream(192.168.6.135, 9999)



    // Create a NetworkInputDStream on target ip:port and count the
    // words in input stream of \n delimited text (eg. generated by 'nc')
    val lines = ssc.socketTextStream(args(1), args(2).toInt, StorageLevel.MEMORY_ONLY_SER)

    //split each line into words
    val words = lines.flatMap(_.split(" "))
    //build wordcount
    val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _)





    // Print a few of the counts to the console
    wordCounts.print()
    ssc.start()             // Start the computation
    ssc.awaitTermination()  // Wait for the computation to

  }
}